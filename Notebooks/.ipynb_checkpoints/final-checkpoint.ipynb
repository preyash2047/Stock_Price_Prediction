{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sudden-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def predict_clossing_price(start_year, start_month, start_day, code):\n",
    "    \n",
    "    start = datetime.datetime(start_year,start_month,start_day)\n",
    "    end = datetime.date.today()\n",
    "    stockData = data.DataReader(code , 'yahoo',start,end)\n",
    "\n",
    "    def get_rsi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        RS = 0\n",
    "        RSI = 100\n",
    "\n",
    "        upcloses = 0\n",
    "        downcloses = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "           diff = sdata[n,3] - sdata[k,3]\n",
    "           if (diff>=0):\n",
    "            upcloses = upcloses + diff\n",
    "            pos = pos+1\n",
    "           else:\n",
    "            downcloses = downcloses + diff\n",
    "            neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        downcloses = -downcloses\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            RS = (upcloses*neg)/(downcloses*pos)\n",
    "\n",
    "\n",
    "        RSI = 100 - (100/(1+RS))\n",
    "\n",
    "        return RSI\n",
    "\n",
    "\n",
    "    def get_mfi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        MFR = 0\n",
    "        MFI = 100\n",
    "\n",
    "        pmflow = 0\n",
    "        nmflow = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "\n",
    "           typ_pricec = (sdata[n,0] + sdata[n,1] + sdata[n,3])/3\n",
    "           typ_pricep = (sdata[k,0] + sdata[k,1] + sdata[k,3])/3\n",
    "\n",
    "          # print(typ_price,sdata[n,0],sdata[n,1],sdata[n,3])\n",
    "\n",
    "           if (typ_pricec>=typ_pricep):\n",
    "             pmflow = pmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             pos = pos+1\n",
    "           else:\n",
    "             nmflow = nmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            MFR = pmflow/nmflow\n",
    "\n",
    "        MFI = 100 - (100/(1+MFR))\n",
    "\n",
    "        return MFI\n",
    "\n",
    "    def get_ema(sdata,m,mem,EMAp):\n",
    "\n",
    "       EMA = sdata[m,3]*(2/(1+mem)) + (1-(2/(1+mem)))*EMAp \n",
    "       #print(\"EMA\",EMA)\n",
    "\n",
    "       return EMA\n",
    "\n",
    "    def get_so(sdata,m,mem):\n",
    "\n",
    "       SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n",
    "       #print(\"SO\",SO)\n",
    "       return SO\n",
    "\n",
    "\n",
    "    memory = 14\n",
    "    sdat2 = stockData.reset_index()\n",
    "    del sdat2[\"Date\"]\n",
    "    del sdat2[\"Adj Close\"]\n",
    "    sdat3 = np.array(sdat2,dtype=np.float32)\n",
    "\n",
    "    #print(sdat3[0])\n",
    "\n",
    "    df1 = pd.DataFrame(columns=['Open','High','Low','Close','Volume','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    df2 = pd.DataFrame(columns=['Close','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    arr = np.array(df1.values)\n",
    "\n",
    "    #print(\"Printing j\\n\")\n",
    "\n",
    "    EMAp = 0\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(memory):\n",
    "        acc = acc + sdat3[i,3]\n",
    "\n",
    "    EMAp = acc / memory    \n",
    "\n",
    "    #for i in range(len(sdat3) -memory):\n",
    "    for i in range(len(sdat3)-1 -memory):\n",
    "        j = i + memory\n",
    "\n",
    "        RSI = get_rsi(sdat3,j,memory)\n",
    "        #print(\"RSI:\",RSI)\n",
    "\n",
    "        MFI = get_mfi(sdat3,j,memory)\n",
    "        #print(\"MFI:\",MFI)\n",
    "\n",
    "        EMA = get_ema(sdat3,j,memory,EMAp)\n",
    "        EMAp = EMA\n",
    "\n",
    "        SO = get_so(sdat3,j,memory)\n",
    "\n",
    "        N_close = sdat3[j+1,3]\n",
    "\n",
    "        rec1 = [sdat3[j,2],sdat3[j,0],sdat3[j,1],sdat3[j,3],sdat3[j,4],RSI,MFI,EMA,SO,N_close]\n",
    "        rec2 = [sdat3[j,3],RSI,MFI,EMA,SO,N_close]\n",
    "\n",
    "        if(sdat3[j,4]!=0):\n",
    "            d1 = {\"Open\":sdat3[j,2],\"High\":sdat3[j,0],\"Low\":sdat3[j,1],\"Close\":sdat3[j,3],\"Volume\":sdat3[j,4],\"RSI\":RSI,\"MFI\":MFI,\"EMA\":EMA,\"SO\":SO,\"CloseNext\":N_close}\n",
    "            df1.loc[i] = rec1\n",
    "            df2.loc[i] = rec2\n",
    "\n",
    "    #ANN\n",
    "    dataset = df1\n",
    "    y = pd.DataFrame(dataset['CloseNext'])\n",
    "    X = dataset.drop(['CloseNext'], axis = 1)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #X = X[1700:2030,:]\n",
    "    #y = y[1700:2030,:]\n",
    "    y = y.flatten()\n",
    "\n",
    "    #Feature scaling\n",
    "    scaled = StandardScaler()\n",
    "    scaled.fit(X)\n",
    "    X = scaled.transform(X)\n",
    "\n",
    "    #Train Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "    ## ANN implementation\n",
    "    # define base model of our neural network for regression taks\n",
    "    def endgame():\n",
    "        # Adding the neurons in various layers\n",
    "        model = Sequential()\n",
    "        model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # Compile model for our use in KerasRegressor\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mape'])\n",
    "        return model\n",
    "\n",
    "    ann_regression = KerasRegressor(build_fn = endgame, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "    ann_regression.fit(X_train,y_train)\n",
    "\n",
    "    ann_predict = ann_regression.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(ann_predict,y_test)\n",
    "    per_err = (error/np.mean(y_test)) * 100\n",
    "    print('The mean absolute error is {} and percentage error is {}.'.format(error,per_err))\n",
    "    \n",
    "    return ann_regression.predict(scaled.transform([df1.iloc[-1,:-1].values.tolist()])), df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unsigned-decimal",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 638.1554 - mape: 99.9984\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 638.2170 - mape: 99.9887\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 640.9576 - mape: 99.9787\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 638.6343 - mape: 99.9686\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 638.8444 - mape: 99.9583\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 638.3773 - mape: 99.9477\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 638.9063 - mape: 99.9369\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 635.7392 - mape: 99.9257\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 637.1082 - mape: 99.9142\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 636.2542 - mape: 99.9016\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 638.0965 - mape: 99.8889\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 634.5817 - mape: 99.8761\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 635.1097 - mape: 99.8632\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 631.5501 - mape: 99.8487\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 635.4037 - mape: 99.8335\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 630.9837 - mape: 99.8173\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 633.2720 - mape: 99.7990\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 631.1949 - mape: 99.7810\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 635.9822 - mape: 99.7601\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 630.1817 - mape: 99.7409\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 632.5076 - mape: 99.7123\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 632.9509 - mape: 99.6933\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 632.5912 - mape: 99.6545\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 635.4312 - mape: 99.6263\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 631.0058 - mape: 99.5949\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 633.9637 - mape: 99.5631\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 633.4731 - mape: 99.5244\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 628.6624 - mape: 99.4763\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 628.4979 - mape: 99.4244\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 627.2490 - mape: 99.3647\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 628.8397 - mape: 99.2936\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 631.2912 - mape: 99.2228\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 628.4769 - mape: 99.1584\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 627.5277 - mape: 99.0472\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 623.4915 - mape: 99.0644\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 623.6285 - mape: 98.9845\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 623.5885 - mape: 98.8629\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 617.7373 - mape: 98.7415\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 618.7890 - mape: 98.7041\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 616.6032 - mape: 98.4558\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 617.2420 - mape: 98.3084\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 613.6249 - mape: 98.2189\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 613.5841 - mape: 97.9913\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 608.7893 - mape: 97.7689\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 605.5606 - mape: 97.6504\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 604.5285 - mape: 97.2458\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 599.9218 - mape: 97.0811\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 597.2282 - mape: 96.8374\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 593.1585 - mape: 96.4018\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 590.6043 - mape: 96.3988\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 585.7547 - mape: 96.1041\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 584.1061 - mape: 95.5266\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 578.9854 - mape: 95.3317\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 577.8279 - mape: 95.1970\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 568.5264 - mape: 94.7118\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 564.9952 - mape: 94.0745\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 561.2423 - mape: 93.8430\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 559.0763 - mape: 93.6475\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 547.2865 - mape: 92.6039\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 539.8169 - mape: 92.1551\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 531.3985 - mape: 91.1521\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 526.0177 - mape: 90.6957\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 517.3729 - mape: 90.1377\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 503.1114 - mape: 88.6199\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 489.1149 - mape: 87.3528\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 482.5255 - mape: 86.9180\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 484.9621 - mape: 86.9754\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 480.7036 - mape: 86.5408\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 458.9633 - mape: 84.4978\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 459.3003 - mape: 84.5211\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 437.6612 - mape: 82.6919\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 422.3002 - mape: 81.0875\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 418.7611 - mape: 80.7559\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 396.0502 - mape: 78.3428\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 387.2586 - mape: 77.3953\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 396.1614 - mape: 78.1281\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 391.9391 - mape: 77.6221\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 363.6509 - mape: 74.4712\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 345.9887 - mape: 72.7089\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 339.1456 - mape: 71.5453\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 328.4381 - mape: 70.1774\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 279.3019 - mape: 64.3809\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 290.2737 - mape: 65.0668\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 255.2998 - mape: 61.3019\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 269.0650 - mape: 62.6067\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 232.8962 - mape: 57.0225\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 213.7916 - mape: 54.2784\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 248.5406 - mape: 58.6297\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 218.1924 - mape: 54.6112\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 210.0219 - mape: 51.9710\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 210.1247 - mape: 52.5781\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 198.1486 - mape: 50.2384\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 186.6978 - mape: 46.8117\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 153.4789 - mape: 42.9199\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 150.6235 - mape: 41.8451\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 178.6437 - mape: 47.5603\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 130.4970 - mape: 38.3023\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 126.1393 - mape: 37.9353\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 149.4206 - mape: 40.6355\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 136.4035 - mape: 39.5711\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "The mean absolute error is 18.35058002471924 and percentage error is 73.84539132000573.\n",
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "#parameter\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "code = \"IRFC.NS\"\n",
    "\n",
    "predicted_price, df1  = predict_clossing_price(start_year, start_month, start_day, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "parliamentary-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dominant-stress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MFI</th>\n",
       "      <th>EMA</th>\n",
       "      <th>SO</th>\n",
       "      <th>CloseNext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.450001</td>\n",
       "      <td>25.799999</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.650000</td>\n",
       "      <td>21022422.0</td>\n",
       "      <td>36.666664</td>\n",
       "      <td>61.104232</td>\n",
       "      <td>25.343571</td>\n",
       "      <td>62.500060</td>\n",
       "      <td>25.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.650000</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>25.200001</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>14542153.0</td>\n",
       "      <td>38.221528</td>\n",
       "      <td>53.581972</td>\n",
       "      <td>25.344428</td>\n",
       "      <td>29.999924</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.299999</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>24.950001</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16652770.0</td>\n",
       "      <td>38.221528</td>\n",
       "      <td>55.834741</td>\n",
       "      <td>25.298505</td>\n",
       "      <td>11.110970</td>\n",
       "      <td>24.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.150000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>24.950001</td>\n",
       "      <td>13021961.0</td>\n",
       "      <td>43.750008</td>\n",
       "      <td>59.829862</td>\n",
       "      <td>25.252037</td>\n",
       "      <td>20.000458</td>\n",
       "      <td>24.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.900000</td>\n",
       "      <td>25.200001</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>10958830.0</td>\n",
       "      <td>35.999992</td>\n",
       "      <td>48.309701</td>\n",
       "      <td>25.205099</td>\n",
       "      <td>14.285481</td>\n",
       "      <td>24.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.950001</td>\n",
       "      <td>25.200001</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>24.950001</td>\n",
       "      <td>22761296.0</td>\n",
       "      <td>30.434792</td>\n",
       "      <td>42.768245</td>\n",
       "      <td>25.171086</td>\n",
       "      <td>16.666985</td>\n",
       "      <td>24.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.850000</td>\n",
       "      <td>24.950001</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>36424500.0</td>\n",
       "      <td>32.258082</td>\n",
       "      <td>41.905552</td>\n",
       "      <td>25.101608</td>\n",
       "      <td>33.333191</td>\n",
       "      <td>25.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.650000</td>\n",
       "      <td>26.700001</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>93579584.0</td>\n",
       "      <td>50.561796</td>\n",
       "      <td>58.286070</td>\n",
       "      <td>25.208060</td>\n",
       "      <td>60.975575</td>\n",
       "      <td>25.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.100000</td>\n",
       "      <td>26.299999</td>\n",
       "      <td>25.450001</td>\n",
       "      <td>25.650000</td>\n",
       "      <td>48494936.0</td>\n",
       "      <td>53.086417</td>\n",
       "      <td>67.838909</td>\n",
       "      <td>25.266985</td>\n",
       "      <td>23.529319</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.799999</td>\n",
       "      <td>25.950001</td>\n",
       "      <td>25.450001</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>18806436.0</td>\n",
       "      <td>58.305088</td>\n",
       "      <td>63.757147</td>\n",
       "      <td>25.298054</td>\n",
       "      <td>9.999847</td>\n",
       "      <td>25.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>21742960.0</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>62.847463</td>\n",
       "      <td>25.311647</td>\n",
       "      <td>33.333191</td>\n",
       "      <td>24.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.400000</td>\n",
       "      <td>25.549999</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>24.950001</td>\n",
       "      <td>25255200.0</td>\n",
       "      <td>63.380293</td>\n",
       "      <td>54.756491</td>\n",
       "      <td>25.263427</td>\n",
       "      <td>20.000203</td>\n",
       "      <td>24.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25.100000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>16353985.0</td>\n",
       "      <td>69.142871</td>\n",
       "      <td>48.380047</td>\n",
       "      <td>25.208304</td>\n",
       "      <td>11.111347</td>\n",
       "      <td>24.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24.950001</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>24.950001</td>\n",
       "      <td>21380756.0</td>\n",
       "      <td>67.567587</td>\n",
       "      <td>54.863393</td>\n",
       "      <td>25.173863</td>\n",
       "      <td>21.428765</td>\n",
       "      <td>24.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>11360743.0</td>\n",
       "      <td>70.000016</td>\n",
       "      <td>50.630725</td>\n",
       "      <td>25.130682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open       High        Low      Close      Volume        RSI  \\\n",
       "0   25.450001  25.799999  25.400000  25.650000  21022422.0  36.666664   \n",
       "1   25.650000  25.700001  25.200001  25.350000  14542153.0  38.221528   \n",
       "2   25.299999  25.400000  24.950001  25.000000  16652770.0  38.221528   \n",
       "3   25.000000  25.150000  24.900000  24.950001  13021961.0  43.750008   \n",
       "4   24.900000  25.200001  24.850000  24.900000  10958830.0  35.999992   \n",
       "5   24.950001  25.200001  24.900000  24.950001  22761296.0  30.434792   \n",
       "6   24.850000  24.950001  24.500000  24.650000  36424500.0  32.258082   \n",
       "7   24.650000  26.700001  24.650000  25.900000  93579584.0  50.561796   \n",
       "8   26.100000  26.299999  25.450001  25.650000  48494936.0  53.086417   \n",
       "9   25.799999  25.950001  25.450001  25.500000  18806436.0  58.305088   \n",
       "10  25.250000  25.700001  25.250000  25.400000  21742960.0  64.285714   \n",
       "11  25.400000  25.549999  24.799999  24.950001  25255200.0  63.380293   \n",
       "12  25.100000  25.250000  24.799999  24.850000  16353985.0  69.142871   \n",
       "13  24.950001  25.500000  24.799999  24.950001  21380756.0  67.567587   \n",
       "14  25.000000  25.100000  24.850000  24.850000  11360743.0  70.000016   \n",
       "\n",
       "          MFI        EMA         SO  CloseNext  \n",
       "0   61.104232  25.343571  62.500060  25.350000  \n",
       "1   53.581972  25.344428  29.999924  25.000000  \n",
       "2   55.834741  25.298505  11.110970  24.950001  \n",
       "3   59.829862  25.252037  20.000458  24.900000  \n",
       "4   48.309701  25.205099  14.285481  24.950001  \n",
       "5   42.768245  25.171086  16.666985  24.650000  \n",
       "6   41.905552  25.101608  33.333191  25.900000  \n",
       "7   58.286070  25.208060  60.975575  25.650000  \n",
       "8   67.838909  25.266985  23.529319  25.500000  \n",
       "9   63.757147  25.298054   9.999847  25.400000  \n",
       "10  62.847463  25.311647  33.333191  24.950001  \n",
       "11  54.756491  25.263427  20.000203  24.850000  \n",
       "12  48.380047  25.208304  11.111347  24.950001  \n",
       "13  54.863393  25.173863  21.428765  24.850000  \n",
       "14  50.630725  25.130682   0.000000  24.850000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-search",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
