{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sudden-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def predict_clossing_price(start_year, start_month, start_day, code):\n",
    "    \n",
    "    start = datetime.datetime(start_year,start_month,start_day)\n",
    "    end = datetime.date.today()\n",
    "    stockData = data.DataReader(code , 'yahoo',start,end)\n",
    "\n",
    "    def get_rsi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        RS = 0\n",
    "        RSI = 100\n",
    "\n",
    "        upcloses = 0\n",
    "        downcloses = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "           diff = sdata[n,3] - sdata[k,3]\n",
    "           if (diff>=0):\n",
    "            upcloses = upcloses + diff\n",
    "            pos = pos+1\n",
    "           else:\n",
    "            downcloses = downcloses + diff\n",
    "            neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        downcloses = -downcloses\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            RS = (upcloses*neg)/(downcloses*pos)\n",
    "\n",
    "\n",
    "        RSI = 100 - (100/(1+RS))\n",
    "\n",
    "        return RSI\n",
    "\n",
    "\n",
    "    def get_mfi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        MFR = 0\n",
    "        MFI = 100\n",
    "\n",
    "        pmflow = 0\n",
    "        nmflow = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "\n",
    "           typ_pricec = (sdata[n,0] + sdata[n,1] + sdata[n,3])/3\n",
    "           typ_pricep = (sdata[k,0] + sdata[k,1] + sdata[k,3])/3\n",
    "\n",
    "          # print(typ_price,sdata[n,0],sdata[n,1],sdata[n,3])\n",
    "\n",
    "           if (typ_pricec>=typ_pricep):\n",
    "             pmflow = pmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             pos = pos+1\n",
    "           else:\n",
    "             nmflow = nmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            MFR = pmflow/nmflow\n",
    "\n",
    "        MFI = 100 - (100/(1+MFR))\n",
    "\n",
    "        return MFI\n",
    "\n",
    "    def get_ema(sdata,m,mem,EMAp):\n",
    "\n",
    "       EMA = sdata[m,3]*(2/(1+mem)) + (1-(2/(1+mem)))*EMAp \n",
    "       #print(\"EMA\",EMA)\n",
    "\n",
    "       return EMA\n",
    "\n",
    "    def get_so(sdata,m,mem):\n",
    "\n",
    "       SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n",
    "       #print(\"SO\",SO)\n",
    "       return SO\n",
    "\n",
    "\n",
    "    memory = 14\n",
    "    sdat2 = stockData.reset_index()\n",
    "    del sdat2[\"Date\"]\n",
    "    del sdat2[\"Adj Close\"]\n",
    "    sdat3 = np.array(sdat2,dtype=np.float32)\n",
    "\n",
    "    #print(sdat3[0])\n",
    "\n",
    "    df1 = pd.DataFrame(columns=['Open','High','Low','Close','Volume','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    df2 = pd.DataFrame(columns=['Close','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    arr = np.array(df1.values)\n",
    "\n",
    "    #print(\"Printing j\\n\")\n",
    "\n",
    "    EMAp = 0\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(memory):\n",
    "        acc = acc + sdat3[i,3]\n",
    "\n",
    "    EMAp = acc / memory    \n",
    "\n",
    "    #for i in range(len(sdat3) -memory):\n",
    "    for i in range(len(sdat3)-1 -memory):\n",
    "        j = i + memory\n",
    "\n",
    "        RSI = get_rsi(sdat3,j,memory)\n",
    "        #print(\"RSI:\",RSI)\n",
    "\n",
    "        MFI = get_mfi(sdat3,j,memory)\n",
    "        #print(\"MFI:\",MFI)\n",
    "\n",
    "        EMA = get_ema(sdat3,j,memory,EMAp)\n",
    "        EMAp = EMA\n",
    "\n",
    "        SO = get_so(sdat3,j,memory)\n",
    "\n",
    "        N_close = sdat3[j+1,3]\n",
    "\n",
    "        rec1 = [sdat3[j,2],sdat3[j,0],sdat3[j,1],sdat3[j,3],sdat3[j,4],RSI,MFI,EMA,SO,N_close]\n",
    "        rec2 = [sdat3[j,3],RSI,MFI,EMA,SO,N_close]\n",
    "\n",
    "        if(sdat3[j,4]!=0):\n",
    "            d1 = {\"Open\":sdat3[j,2],\"High\":sdat3[j,0],\"Low\":sdat3[j,1],\"Close\":sdat3[j,3],\"Volume\":sdat3[j,4],\"RSI\":RSI,\"MFI\":MFI,\"EMA\":EMA,\"SO\":SO,\"CloseNext\":N_close}\n",
    "            df1.loc[i] = rec1\n",
    "            df2.loc[i] = rec2\n",
    "\n",
    "    #ANN\n",
    "    dataset = df1\n",
    "    y = pd.DataFrame(dataset['CloseNext'])\n",
    "    X = dataset.drop(['CloseNext'], axis = 1)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #X = X[1700:2030,:]\n",
    "    #y = y[1700:2030,:]\n",
    "    y = y.flatten()\n",
    "\n",
    "    #Feature scaling\n",
    "    scaled = StandardScaler()\n",
    "    scaled.fit(X)\n",
    "    X = scaled.transform(X)\n",
    "\n",
    "    #Train Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "    ## ANN implementation\n",
    "    # define base model of our neural network for regression taks\n",
    "    def endgame():\n",
    "        # Adding the neurons in various layers\n",
    "        model = Sequential()\n",
    "        model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # Compile model for our use in KerasRegressor\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mape'])\n",
    "        return model\n",
    "\n",
    "    ann_regression = KerasRegressor(build_fn = endgame, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "    ann_regression.fit(X_train,y_train)\n",
    "\n",
    "    ann_predict = ann_regression.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(ann_predict,y_test)\n",
    "    per_err = (error/np.mean(y_test)) * 100\n",
    "    print('The mean absolute error is {} and percentage error is {}.'.format(error,per_err))\n",
    "    \n",
    "    return ann_regression.predict(scaled.transform([df1.iloc[-1,:-1].values.tolist()])), df1.iloc[-1,:], error,per_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "unsigned-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "code = \"IRFC.NS\"\n",
    "\n",
    "#predicted_price, df1  = predict_clossing_price(start_year, start_month, start_day, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f7748bae37fd>:104: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "93/93 [==============================] - 1s 1ms/step - loss: nan - mape: nan       \n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan: 0s - loss: nan - mape:\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 0s 2ms/step - loss: nan - mape: nan\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 0s 1ms/step - loss: nan - mape: nan\n",
      "40/40 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f7748bae37fd>:104: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 5201.6927 - mape: 91.1358\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 277.5519 - mape: 24.9070\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 107.1493 - mape: 18.7181\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 51.1878 - mape: 13.1804\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 25.4635 - mape: 9.8465\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 12.0957 - mape: 7.0924\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 6.8639 - mape: 4.9176\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 5.8778 - mape: 3.5235\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 5.2390 - mape: 3.0783\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.3039 - mape: 2.7646\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2400 - mape: 2.6134\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2118 - mape: 2.6609\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.8950 - mape: 2.4787\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.6140 - mape: 2.4381\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.1500 - mape: 2.5294\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.9601 - mape: 2.4407\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5094 - mape: 2.4304\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.3695 - mape: 2.4226\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.8015 - mape: 2.4795\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5093 - mape: 2.3688\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.8589 - mape: 2.4255\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2052 - mape: 2.3561\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.6491 - mape: 2.5275\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 4.5580 - mape: 2.3796\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.4177 - mape: 2.4229\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5002 - mape: 2.3453\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.6228 - mape: 2.3921\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.7058 - mape: 2.1974\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.7311 - mape: 2.1971\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9925 - mape: 2.3068\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.7316 - mape: 2.3479\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0117 - mape: 2.2798\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.4469 - mape: 2.2937\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2892 - mape: 2.2701\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.5360 - mape: 2.2367\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.3493 - mape: 2.2955\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9594 - mape: 2.2093\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.8262 - mape: 2.2878\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9072 - mape: 2.1786\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.6248 - mape: 2.3606\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.6387 - mape: 2.2115\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.7169 - mape: 2.0755\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.8096 - mape: 2.5352\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0959 - mape: 2.2440\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5531 - mape: 2.1997\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9897 - mape: 2.2542\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2768 - mape: 2.3894\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0394 - mape: 2.2701\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.1960 - mape: 2.4080\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9309 - mape: 2.2217\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 5.1170 - mape: 2.4507\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.3568 - mape: 2.2556\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.7635 - mape: 2.1477\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 5.0072 - mape: 2.3569\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5173 - mape: 2.3089\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2015 - mape: 2.1827\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.6723 - mape: 2.2548\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.1544 - mape: 2.2332\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3.8489 - mape: 2.1583\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9980 - mape: 2.2935\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3.9643 - mape: 2.2290\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2571 - mape: 2.2390\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5053 - mape: 2.2207\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5127 - mape: 2.2543\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2877 - mape: 2.2166\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 4.0632 - mape: 2.3060\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 4.3125 - mape: 2.2196\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3.7966 - mape: 2.2569\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.4720 - mape: 2.3333\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.8769 - mape: 2.1610\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9894 - mape: 2.1668\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0632 - mape: 2.2431\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 4.5468 - mape: 2.2012\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 4.2989 - mape: 2.1995\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.5083 - mape: 2.2066\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 4.1045 - mape: 2.1974\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3.9391 - mape: 2.1849\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3.9161 - mape: 2.1944\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9590 - mape: 2.2387\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 4.7861 - mape: 2.3932\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9362 - mape: 2.0717\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0097 - mape: 2.2493\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.4824 - mape: 2.1615\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 0s 1ms/step - loss: 3.8714 - mape: 2.1988\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.4345 - mape: 2.2216\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0039 - mape: 2.2419\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.2369 - mape: 2.2088\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0275 - mape: 2.1939\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0781 - mape: 2.2770\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.7501 - mape: 2.2590\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9505 - mape: 2.3386\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.8517 - mape: 2.1812\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.7074 - mape: 2.1964\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.8792 - mape: 2.1563\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.0619 - mape: 2.2675\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4.3530 - mape: 2.1812\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3.9173 - mape: 2.1852\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3.9009 - mape: 2.1980\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 4.4474 - mape: 2.1680\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 4.4362 - mape: 2.2081\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "The mean absolute error is 1.5416412035199765 and percentage error is 2.313016899231881.\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f7748bae37fd>:104: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3863992.5051 - mape: 99.1546\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2066239.1396 - mape: 71.0058\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 178980.5822 - mape: 92.4812\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 127138.3132 - mape: 84.1043\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 92199.2015 - mape: 79.2528\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 60893.2235 - mape: 81.1705\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 42696.0244 - mape: 80.1901\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 27900.4146 - mape: 70.8783\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 16208.4010 - mape: 56.0750\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 8918.1433 - mape: 45.3514\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 5696.2095 - mape: 29.9567\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 5255.3826 - mape: 22.7946\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 4803.6036 - mape: 17.7414\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3708.9007 - mape: 14.7337\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3043.0033 - mape: 10.8087\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3349.7725 - mape: 10.4105\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4627.0495 - mape: 9.7412\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3964.9205 - mape: 8.5557\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3778.2233 - mape: 7.8275\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3596.6735 - mape: 7.5635\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3031.1076 - mape: 6.8827\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3720.7080 - mape: 7.3166\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3843.3440 - mape: 6.7300\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3757.4002 - mape: 6.6299\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3671.6472 - mape: 6.3159\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3140.8097 - mape: 6.3716\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2801.8093 - mape: 5.9228\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2400.2829 - mape: 6.0166\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3707.1611 - mape: 6.4953\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2767.8848 - mape: 5.5785\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2639.5609 - mape: 5.1996\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2779.0136 - mape: 5.6455\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3417.8796 - mape: 5.9482\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2961.8776 - mape: 5.8446\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3871.5849 - mape: 5.7777\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3125.9424 - mape: 5.4510\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3611.9916 - mape: 6.1263\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3216.1769 - mape: 5.2998\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3413.7077 - mape: 5.9161\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3131.7858 - mape: 5.3182\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2897.7008 - mape: 5.6035\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3458.1343 - mape: 5.9914\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3169.4430 - mape: 5.8239\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2696.2716 - mape: 5.4769\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - ETA: 0s - loss: 4048.8739 - mape: 5.284 - 0s 1ms/step - loss: 3959.1513 - mape: 5.2882\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2715.9937 - mape: 5.3163\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3079.6524 - mape: 5.4335\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3347.8772 - mape: 5.3651\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3435.2360 - mape: 5.3978\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 2932.1797 - mape: 4.8329\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3400.6875 - mape: 5.8638\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3488.0317 - mape: 5.3154\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2900.8201 - mape: 5.4791\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3496.7198 - mape: 5.5516\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 3415.8763 - mape: 4.9765\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3599.0230 - mape: 5.3836\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2791.3400 - mape: 5.2576\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2471.5965 - mape: 4.8560\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2732.7983 - mape: 5.4189\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2773.6846 - mape: 4.8992\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3044.7969 - mape: 4.6713\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3277.5382 - mape: 4.8678\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3247.9340 - mape: 5.1578\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4007.8017 - mape: 4.9439\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2761.7516 - mape: 4.1490\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2854.2450 - mape: 4.5269\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3801.8221 - mape: 4.5446\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2745.1695 - mape: 4.0742\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3160.2066 - mape: 4.3118\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2853.8309 - mape: 4.0948\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2804.6720 - mape: 4.1015\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2816.5281 - mape: 4.1344\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3016.8720 - mape: 4.1523\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2646.1363 - mape: 3.8840\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2401.0679 - mape: 3.5395\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2741.6514 - mape: 3.6002\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3090.1775 - mape: 3.5402\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3080.1184 - mape: 4.0942\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2556.7046 - mape: 3.5422\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3027.8870 - mape: 3.8419\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 0s 1ms/step - loss: 3527.5433 - mape: 3.6426\n",
      "Epoch 82/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2535.8089 - mape: 3.5005\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 3056.4359 - mape: 3.5028\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2912.8914 - mape: 3.5428\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2892.6876 - mape: 3.9682\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2753.8407 - mape: 3.8010\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2639.3494 - mape: 3.6654\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2774.5473 - mape: 3.4623\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2897.5083 - mape: 3.5128\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3080.9230 - mape: 3.6190\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3295.4700 - mape: 3.9405\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2689.9275 - mape: 3.6255\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2677.0324 - mape: 3.8826\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3053.9563 - mape: 3.5769\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2812.0466 - mape: 3.4033\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2969.8522 - mape: 3.9145\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 1s 3ms/step - loss: 3248.3187 - mape: 3.6448\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2904.3781 - mape: 3.3403\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 3125.1900 - mape: 3.8182\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 2876.1447 - mape: 3.3853\n",
      "150/150 [==============================] - 0s 2ms/step\n",
      "The mean absolute error is 25.243873616563622 and percentage error is 1.9715827897664562.\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f7748bae37fd>:104: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 18816.2115 - mape: 95.6276\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4020.5404 - mape: 45.5073\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 1858.3430 - mape: 30.2716\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 232.2827 - mape: 10.0028\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 88.5005 - mape: 6.4264\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 48.6826 - mape: 4.7674\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 32.2534 - mape: 3.8474\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 25.3358 - mape: 3.3186\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 19.6513 - mape: 2.9973\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 19.4576 - mape: 2.6675\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 16.7135 - mape: 2.5647\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 15.5354 - mape: 2.3349\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 14.8136 - mape: 2.2981\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 14.1558 - mape: 2.2499\n",
      "Epoch 15/100\n",
      " 34/349 [=>............................] - ETA: 0s - loss: 14.5585 - mape: 2.4151"
     ]
    }
   ],
   "source": [
    "list_of_stock_code = [\"IOC.NS\", \"INFY.NS\", \"HCLTECH.NS\", \"SBIN.NS\", \"SBICARD.NS\", \"SBILIFE.NS\", \"ITC.NS\", \"TECHM.NS\", \n",
    "                     \"RELIANCEPP-E1.NS\", \"WIPRO.NS\", \"RELIANCE.NS\", \"IBM\", \"GOOG\", \"HINDUNILVR.NS\", \"HINDPETRO.NS\",\n",
    "                      \"HINDALCO.NS\", \"HDFCAMC.NS\", \"HDFC.NS\", \"BANKBARODA.NS\", \"YESBANK.NS\", \"ASHOKLEY.NS\", \"MOTHERSUMI.NS\",\n",
    "                      \"IRCTC.NS\", \"BEPL.NS\", \"TATAPOWER.NS\", \"BAJFINANCE.NS\", \"ONGC.NS\", \"SUNPHARMA.NS\", \"COALINDIA.NS\", \n",
    "                      \"ADANIGREEN.NS\", \"DRREDDY.NS\", \"JUBLFOOD.NS\", \"WESTLIFE.NS\", \"TCS.NS\", \"TATACONSUM.NS\", \"SRTRANSFIN.NS\"]\n",
    "\n",
    "list_of_stock_code = np.unique(list_of_stock_code)\n",
    "\n",
    "#parameter\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "\n",
    "data_values = []\n",
    "\n",
    "error_code = []\n",
    "for code in list_of_stock_code:\n",
    "    try:\n",
    "        predicted_price, df1, error,per_err  = predict_clossing_price(start_year, start_month, start_day, code)\n",
    "        data_values.append([\n",
    "            code, \n",
    "            round(float(df1.Close),2),\n",
    "            round(float(predicted_price),2),\n",
    "            round(float(error),2),\n",
    "            round(float(per_err),2),\n",
    "            0])\n",
    "    except:\n",
    "        error_code.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns = [\"symbol\", \"Clossing_Price\", \"Predicted_Price\",\"Error\", \"Error_in_per\", \"Actual_Price\"], data = data_values)\n",
    "dataset.to_csv(\"stock_price_prediction_16_march_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reserved-election",
   "metadata": {},
   "source": [
    "# Storing the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "national-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "report = pd.read_csv(\"stock_price_prediction_13_march_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blessed-albuquerque",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>Clossing_Price</th>\n",
       "      <th>Predicted_Price</th>\n",
       "      <th>Error</th>\n",
       "      <th>Error_in_per</th>\n",
       "      <th>Actual_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASHOKLEY.NS</td>\n",
       "      <td>123.90</td>\n",
       "      <td>124.41</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>5545.05</td>\n",
       "      <td>5453.51</td>\n",
       "      <td>25.88</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANKBARODA.NS</td>\n",
       "      <td>80.00</td>\n",
       "      <td>77.95</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COALINDIA.NS</td>\n",
       "      <td>150.95</td>\n",
       "      <td>148.45</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DRREDDY.NS</td>\n",
       "      <td>4500.40</td>\n",
       "      <td>4536.87</td>\n",
       "      <td>36.68</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2114.77</td>\n",
       "      <td>2112.03</td>\n",
       "      <td>9.77</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HCLTECH.NS</td>\n",
       "      <td>988.50</td>\n",
       "      <td>986.57</td>\n",
       "      <td>5.47</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HDFC.NS</td>\n",
       "      <td>2599.80</td>\n",
       "      <td>2617.71</td>\n",
       "      <td>19.30</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HDFCAMC.NS</td>\n",
       "      <td>3118.50</td>\n",
       "      <td>3094.21</td>\n",
       "      <td>43.26</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HINDALCO.NS</td>\n",
       "      <td>340.35</td>\n",
       "      <td>337.59</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HINDPETRO.NS</td>\n",
       "      <td>241.00</td>\n",
       "      <td>242.45</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HINDUNILVR.NS</td>\n",
       "      <td>2227.85</td>\n",
       "      <td>2223.27</td>\n",
       "      <td>12.39</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IBM</td>\n",
       "      <td>127.14</td>\n",
       "      <td>127.74</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INFY.NS</td>\n",
       "      <td>1368.15</td>\n",
       "      <td>1344.38</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IOC.NS</td>\n",
       "      <td>98.85</td>\n",
       "      <td>98.79</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ITC.NS</td>\n",
       "      <td>206.50</td>\n",
       "      <td>207.34</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MOTHERSUMI.NS</td>\n",
       "      <td>219.00</td>\n",
       "      <td>216.82</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ONGC.NS</td>\n",
       "      <td>114.40</td>\n",
       "      <td>112.56</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RELIANCE.NS</td>\n",
       "      <td>2181.95</td>\n",
       "      <td>2198.98</td>\n",
       "      <td>11.79</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SBICARD.NS</td>\n",
       "      <td>1027.35</td>\n",
       "      <td>1031.77</td>\n",
       "      <td>21.93</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SBILIFE.NS</td>\n",
       "      <td>940.75</td>\n",
       "      <td>945.22</td>\n",
       "      <td>10.06</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SBIN.NS</td>\n",
       "      <td>387.70</td>\n",
       "      <td>388.10</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SRTRANSFIN.NS</td>\n",
       "      <td>1315.40</td>\n",
       "      <td>1322.52</td>\n",
       "      <td>17.97</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SUNPHARMA.NS</td>\n",
       "      <td>626.00</td>\n",
       "      <td>631.20</td>\n",
       "      <td>9.14</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TATACONSUM.NS</td>\n",
       "      <td>620.95</td>\n",
       "      <td>620.82</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TATAPOWER.NS</td>\n",
       "      <td>107.35</td>\n",
       "      <td>108.54</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>3070.95</td>\n",
       "      <td>3066.51</td>\n",
       "      <td>18.81</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TECHM.NS</td>\n",
       "      <td>1008.75</td>\n",
       "      <td>1021.45</td>\n",
       "      <td>8.29</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>WESTLIFE.NS</td>\n",
       "      <td>524.30</td>\n",
       "      <td>533.13</td>\n",
       "      <td>8.31</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>426.70</td>\n",
       "      <td>428.77</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           symbol  Clossing_Price  Predicted_Price  Error  Error_in_per  \\\n",
       "0     ASHOKLEY.NS          123.90           124.41   1.30          1.91   \n",
       "1   BAJFINANCE.NS         5545.05          5453.51  25.88          1.99   \n",
       "2   BANKBARODA.NS           80.00            77.95   2.73          1.99   \n",
       "3    COALINDIA.NS          150.95           148.45   4.42          1.52   \n",
       "4      DRREDDY.NS         4500.40          4536.87  36.68          1.36   \n",
       "5            GOOG         2114.77          2112.03   9.77          1.24   \n",
       "6      HCLTECH.NS          988.50           986.57   5.47          1.38   \n",
       "7         HDFC.NS         2599.80          2617.71  19.30          1.39   \n",
       "8      HDFCAMC.NS         3118.50          3094.21  43.26          1.86   \n",
       "9     HINDALCO.NS          340.35           337.59   3.01          1.88   \n",
       "10   HINDPETRO.NS          241.00           242.45   3.63          2.00   \n",
       "11  HINDUNILVR.NS         2227.85          2223.27  12.39          1.17   \n",
       "12            IBM          127.14           127.74   1.57          0.98   \n",
       "13        INFY.NS         1368.15          1344.38   9.57          1.77   \n",
       "14         IOC.NS           98.85            98.79   1.66          1.51   \n",
       "15         ITC.NS          206.50           207.34   3.01          1.35   \n",
       "16  MOTHERSUMI.NS          219.00           216.82   2.35          2.06   \n",
       "17        ONGC.NS          114.40           112.56   2.69          1.57   \n",
       "18    RELIANCE.NS         2181.95          2198.98  11.79          1.55   \n",
       "19     SBICARD.NS         1027.35          1031.77  21.93          2.69   \n",
       "20     SBILIFE.NS          940.75           945.22  10.06          1.34   \n",
       "21        SBIN.NS          387.70           388.10   3.99          1.65   \n",
       "22  SRTRANSFIN.NS         1315.40          1322.52  17.97          1.95   \n",
       "23   SUNPHARMA.NS          626.00           631.20   9.14          1.69   \n",
       "24  TATACONSUM.NS          620.95           620.82   3.44          1.71   \n",
       "25   TATAPOWER.NS          107.35           108.54   1.30          1.63   \n",
       "26         TCS.NS         3070.95          3066.51  18.81          1.36   \n",
       "27       TECHM.NS         1008.75          1021.45   8.29          1.70   \n",
       "28    WESTLIFE.NS          524.30           533.13   8.31          2.28   \n",
       "29       WIPRO.NS          426.70           428.77   2.54          1.23   \n",
       "\n",
       "    Actual_Price  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  \n",
       "10             0  \n",
       "11             0  \n",
       "12             0  \n",
       "13             0  \n",
       "14             0  \n",
       "15             0  \n",
       "16             0  \n",
       "17             0  \n",
       "18             0  \n",
       "19             0  \n",
       "20             0  \n",
       "21             0  \n",
       "22             0  \n",
       "23             0  \n",
       "24             0  \n",
       "25             0  \n",
       "26             0  \n",
       "27             0  \n",
       "28             0  \n",
       "29             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = report.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "satellite-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = []\n",
    "error_code = []\n",
    "\n",
    "for code in report.symbol:\n",
    "    try:\n",
    "        today = datetime.date.today()\n",
    "        stockData = data.DataReader(code , 'yahoo',today,today)\n",
    "        data_values.append([int(stockData.High), int(stockData.Low)])\n",
    "    except:\n",
    "        error_code.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "portable-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "del report[\"Actual_Price\"]\n",
    "\n",
    "report[\"Actual_High\"] = [high[0] for high in data_values]\n",
    "report[\"Actual_Low\"] = [low[1] for low in data_values]\n",
    "\n",
    "data_values_tf = (report.Predicted_Price <= report.Actual_High , report.Actual_Low <= report.Predicted_Price)\n",
    "\n",
    "tf = []\n",
    "for i,j in zip(data_values_tf[0], data_values_tf[1]):\n",
    "    if all([i,j]):\n",
    "        tf.append(True)\n",
    "    else:\n",
    "        tf.append(False)\n",
    "        \n",
    "report[\"Result\"] = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acceptable-validation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "northern-sewing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "frank-notebook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-squad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
