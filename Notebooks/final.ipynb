{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sudden-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "def predict_clossing_price(start_year, start_month, start_day, code):\n",
    "    \n",
    "    start = datetime.datetime(start_year,start_month,start_day)\n",
    "    end = datetime.date.today()\n",
    "    stockData = data.DataReader(code , 'yahoo',start,end)\n",
    "\n",
    "    def get_rsi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        RS = 0\n",
    "        RSI = 100\n",
    "\n",
    "        upcloses = 0\n",
    "        downcloses = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "           diff = sdata[n,3] - sdata[k,3]\n",
    "           if (diff>=0):\n",
    "            upcloses = upcloses + diff\n",
    "            pos = pos+1\n",
    "           else:\n",
    "            downcloses = downcloses + diff\n",
    "            neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        downcloses = -downcloses\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            RS = (upcloses*neg)/(downcloses*pos)\n",
    "\n",
    "\n",
    "        RSI = 100 - (100/(1+RS))\n",
    "\n",
    "        return RSI\n",
    "\n",
    "\n",
    "    def get_mfi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        MFR = 0\n",
    "        MFI = 100\n",
    "\n",
    "        pmflow = 0\n",
    "        nmflow = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "\n",
    "           typ_pricec = (sdata[n,0] + sdata[n,1] + sdata[n,3])/3\n",
    "           typ_pricep = (sdata[k,0] + sdata[k,1] + sdata[k,3])/3\n",
    "\n",
    "          # print(typ_price,sdata[n,0],sdata[n,1],sdata[n,3])\n",
    "\n",
    "           if (typ_pricec>=typ_pricep):\n",
    "             pmflow = pmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             pos = pos+1\n",
    "           else:\n",
    "             nmflow = nmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            MFR = pmflow/nmflow\n",
    "\n",
    "        MFI = 100 - (100/(1+MFR))\n",
    "\n",
    "        return MFI\n",
    "\n",
    "    def get_ema(sdata,m,mem,EMAp):\n",
    "\n",
    "       EMA = sdata[m,3]*(2/(1+mem)) + (1-(2/(1+mem)))*EMAp \n",
    "       #print(\"EMA\",EMA)\n",
    "\n",
    "       return EMA\n",
    "\n",
    "    def get_so(sdata,m,mem):\n",
    "\n",
    "       SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n",
    "       #print(\"SO\",SO)\n",
    "       return SO\n",
    "\n",
    "\n",
    "    memory = 14\n",
    "    sdat2 = stockData.reset_index()\n",
    "    del sdat2[\"Date\"]\n",
    "    del sdat2[\"Adj Close\"]\n",
    "    sdat3 = np.array(sdat2,dtype=np.float32)\n",
    "\n",
    "    #print(sdat3[0])\n",
    "\n",
    "    df1 = pd.DataFrame(columns=['Open','High','Low','Close','Volume','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    df2 = pd.DataFrame(columns=['Close','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    arr = np.array(df1.values)\n",
    "\n",
    "    #print(\"Printing j\\n\")\n",
    "\n",
    "    EMAp = 0\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(memory):\n",
    "        acc = acc + sdat3[i,3]\n",
    "\n",
    "    EMAp = acc / memory    \n",
    "\n",
    "    #for i in range(len(sdat3) -memory):\n",
    "    for i in range(len(sdat3)-1 -memory):\n",
    "        j = i + memory\n",
    "\n",
    "        RSI = get_rsi(sdat3,j,memory)\n",
    "        #print(\"RSI:\",RSI)\n",
    "\n",
    "        MFI = get_mfi(sdat3,j,memory)\n",
    "        #print(\"MFI:\",MFI)\n",
    "\n",
    "        EMA = get_ema(sdat3,j,memory,EMAp)\n",
    "        EMAp = EMA\n",
    "\n",
    "        SO = get_so(sdat3,j,memory)\n",
    "\n",
    "        N_close = sdat3[j+1,3]\n",
    "\n",
    "        rec1 = [sdat3[j,2],sdat3[j,0],sdat3[j,1],sdat3[j,3],sdat3[j,4],RSI,MFI,EMA,SO,N_close]\n",
    "        rec2 = [sdat3[j,3],RSI,MFI,EMA,SO,N_close]\n",
    "\n",
    "        if(sdat3[j,4]!=0):\n",
    "            d1 = {\"Open\":sdat3[j,2],\"High\":sdat3[j,0],\"Low\":sdat3[j,1],\"Close\":sdat3[j,3],\"Volume\":sdat3[j,4],\"RSI\":RSI,\"MFI\":MFI,\"EMA\":EMA,\"SO\":SO,\"CloseNext\":N_close}\n",
    "            df1.loc[i] = rec1\n",
    "            df2.loc[i] = rec2\n",
    "\n",
    "    #ANN\n",
    "    dataset = df1\n",
    "    y = pd.DataFrame(dataset['CloseNext'])\n",
    "    X = dataset.drop(['CloseNext'], axis = 1)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #X = X[1700:2030,:]\n",
    "    #y = y[1700:2030,:]\n",
    "    y = y.flatten()\n",
    "\n",
    "    #Feature scaling\n",
    "    scaled = StandardScaler()\n",
    "    scaled.fit(X)\n",
    "    X = scaled.transform(X)\n",
    "\n",
    "    #Train Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "    ## ANN implementation\n",
    "    # define base model of our neural network for regression taks\n",
    "    def endgame():\n",
    "        # Adding the neurons in various layers\n",
    "        model = Sequential()\n",
    "        model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # Compile model for our use in KerasRegressor\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mape'])\n",
    "        return model\n",
    "\n",
    "    ann_regression = KerasRegressor(build_fn = endgame, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "    ann_regression.fit(X_train,y_train)\n",
    "\n",
    "    ann_predict = ann_regression.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(ann_predict,y_test)\n",
    "    per_err = (error/np.mean(y_test)) * 100\n",
    "    print('The mean absolute error is {} and percentage error is {}.'.format(error,per_err))\n",
    "    \n",
    "    return ann_regression.predict(scaled.transform([df1.iloc[-1,:-1].values.tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-decimal",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f078d159c202>:104: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 830613.9363 - mape: 99.2877\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 261118.0811 - mape: 55.1514\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 40779.1868 - mape: 21.0847\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 31893.8507 - mape: 19.0618\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 19776.5250 - mape: 16.0733\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 13724.4165 - mape: 13.4543\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 5591.2100 - mape: 8.4283\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 2281.7259 - mape: 5.4138\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 1389.1259 - mape: 3.7015\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 720.1043 - mape: 2.6110\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 560.7942 - mape: 1.9460\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 346.3989 - mape: 1.8496\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 415.6404 - mape: 1.8020\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 379.6180 - mape: 1.5937\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 440.0828 - mape: 1.6125\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 334.6629 - mape: 1.5793\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 330.6275 - mape: 1.5207\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 425.5971 - mape: 1.6095\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 339.4709 - mape: 1.5890\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 401.8398 - mape: 1.5687\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 367.5459 - mape: 1.5633\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 498.7715 - mape: 1.7180\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 379.2721 - mape: 1.5373\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 430.0494 - mape: 1.6094\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 482.2445 - mape: 1.6130\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 384.5013 - mape: 1.5683\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 358.4865 - mape: 1.5590\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 381.4202 - mape: 1.5963\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 472.6300 - mape: 1.5693\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 360.0853 - mape: 1.5386\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 377.4447 - mape: 1.5575\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 349.8829 - mape: 1.5786\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 424.7255 - mape: 1.5638\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 431.9517 - mape: 1.5987\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 332.9563 - mape: 1.4943\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 369.5223 - mape: 1.5469\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 351.6753 - mape: 1.5221\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 396.8851 - mape: 1.5515\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 372.8076 - mape: 1.5400\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 371.4802 - mape: 1.5489\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 435.9081 - mape: 1.5743\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 447.0361 - mape: 1.5941\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 491.8949 - mape: 1.6322\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 365.5260 - mape: 1.5152\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 344.6984 - mape: 1.4571\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 383.5996 - mape: 1.5182\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 318.4225 - mape: 1.4586\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 359.9863 - mape: 1.5524\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 333.4527 - mape: 1.5683\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 338.9290 - mape: 1.5033\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 534.3736 - mape: 1.6893\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 361.9877 - mape: 1.5226\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 384.8061 - mape: 1.5495\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 319.4609 - mape: 1.4592\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 420.1376 - mape: 1.6266\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 332.3099 - mape: 1.4848\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 337.9415 - mape: 1.4988\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 366.0058 - mape: 1.4666\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 372.9214 - mape: 1.5385\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 459.3000 - mape: 1.5115\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 321.3387 - mape: 1.4363\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 396.6868 - mape: 1.5539\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 392.0928 - mape: 1.5735\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 332.2509 - mape: 1.4548\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 379.6535 - mape: 1.5470\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 427.5226 - mape: 1.5231\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 329.9149 - mape: 1.5318\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 381.5865 - mape: 1.5588\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 309.2525 - mape: 1.4394\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 407.6223 - mape: 1.5736\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 321.5819 - mape: 1.4277\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 377.8712 - mape: 1.5321\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 429.5805 - mape: 1.4843\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 323.5401 - mape: 1.4691\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 355.7233 - mape: 1.5123\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 350.2109 - mape: 1.4977\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 448.4627 - mape: 1.5601\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 428.7340 - mape: 1.5621\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 369.1136 - mape: 1.5032\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 487.2469 - mape: 1.5608\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 406.6904 - mape: 1.5536\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 0s 1ms/step - loss: 368.3814 - mape: 1.4833\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 289.6273 - mape: 1.3904\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 348.5240 - mape: 1.4881\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 258.5772 - mape: 1.4193\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 359.5942 - mape: 1.5372\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 336.8454 - mape: 1.4475\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 369.6389 - mape: 1.4592\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 362.4246 - mape: 1.5096\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 335.9230 - mape: 1.4270\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 356.5862 - mape: 1.5087\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 376.0927 - mape: 1.5152\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 388.3956 - mape: 1.4952\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 334.2270 - mape: 1.4872\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 372.8442 - mape: 1.4355\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 323.4099 - mape: 1.4469\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 401.4878 - mape: 1.5010\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 373.5590 - mape: 1.5522\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 413.3117 - mape: 1.5515\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 325.1715 - mape: 1.3992\n",
      "150/150 [==============================] - 0s 992us/step\n",
      "The mean absolute error is 11.853795872652594 and percentage error is 1.5351397083690286.\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "#parameter\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "code = \"RELIANCE.NS\"\n",
    "\n",
    "predicted_price  = predict_clossing_price(start_year, start_month, start_day, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "parliamentary-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2183"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-springer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
