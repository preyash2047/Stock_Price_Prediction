{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "surgical-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "front-minutes",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_clossing_price(start_year, start_month, start_day, code):\n",
    "    \n",
    "    start = datetime.datetime(start_year,start_month,start_day)\n",
    "    end = datetime.date.today()\n",
    "    stockData = data.DataReader(code , 'yahoo',start,end)\n",
    "\n",
    "    def get_rsi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        RS = 0\n",
    "        RSI = 100\n",
    "\n",
    "        upcloses = 0\n",
    "        downcloses = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "           diff = sdata[n,3] - sdata[k,3]\n",
    "           if (diff>=0):\n",
    "            upcloses = upcloses + diff\n",
    "            pos = pos+1\n",
    "           else:\n",
    "            downcloses = downcloses + diff\n",
    "            neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        downcloses = -downcloses\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            RS = (upcloses*neg)/(downcloses*pos)\n",
    "\n",
    "\n",
    "        RSI = 100 - (100/(1+RS))\n",
    "\n",
    "        return RSI\n",
    "\n",
    "\n",
    "    def get_mfi(sdata,m,mem):\n",
    "        neg = 0\n",
    "        pos = 0\n",
    "        MFR = 0\n",
    "        MFI = 100\n",
    "\n",
    "        pmflow = 0\n",
    "        nmflow = 0\n",
    "\n",
    "        n = m\n",
    "        k = m-1\n",
    "\n",
    "        for p in range(mem):\n",
    "\n",
    "           typ_pricec = (sdata[n,0] + sdata[n,1] + sdata[n,3])/3\n",
    "           typ_pricep = (sdata[k,0] + sdata[k,1] + sdata[k,3])/3\n",
    "\n",
    "          # print(typ_price,sdata[n,0],sdata[n,1],sdata[n,3])\n",
    "\n",
    "           if (typ_pricec>=typ_pricep):\n",
    "             pmflow = pmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             pos = pos+1\n",
    "           else:\n",
    "             nmflow = nmflow + ((sdata[n,4])*(typ_pricec))\n",
    "             neg = neg+1\n",
    "\n",
    "           n = n-1\n",
    "           k = k-1\n",
    "\n",
    "        if(neg == 0):\n",
    "            return 100\n",
    "        else:\n",
    "            MFR = pmflow/nmflow\n",
    "\n",
    "        MFI = 100 - (100/(1+MFR))\n",
    "\n",
    "        return MFI\n",
    "\n",
    "    def get_ema(sdata,m,mem,EMAp):\n",
    "\n",
    "       EMA = sdata[m,3]*(2/(1+mem)) + (1-(2/(1+mem)))*EMAp \n",
    "       #print(\"EMA\",EMA)\n",
    "\n",
    "       return EMA\n",
    "\n",
    "    def get_so(sdata,m,mem):\n",
    "\n",
    "       SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n",
    "       #print(\"SO\",SO)\n",
    "       return SO\n",
    "\n",
    "\n",
    "    memory = 14\n",
    "    sdat2 = stockData.reset_index()\n",
    "    del sdat2[\"Date\"]\n",
    "    del sdat2[\"Adj Close\"]\n",
    "    sdat3 = np.array(sdat2,dtype=np.float32)\n",
    "\n",
    "    #print(sdat3[0])\n",
    "\n",
    "    df1 = pd.DataFrame(columns=['Open','High','Low','Close','Volume','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    df2 = pd.DataFrame(columns=['Close','RSI','MFI','EMA','SO','CloseNext'])\n",
    "\n",
    "    arr = np.array(df1.values)\n",
    "\n",
    "    #print(\"Printing j\\n\")\n",
    "\n",
    "    EMAp = 0\n",
    "    acc = 0\n",
    "\n",
    "    for i in range(memory):\n",
    "        acc = acc + sdat3[i,3]\n",
    "\n",
    "    EMAp = acc / memory    \n",
    "\n",
    "    #for i in range(len(sdat3) -memory):\n",
    "    for i in range(len(sdat3)-1 -memory):\n",
    "        j = i + memory\n",
    "\n",
    "        RSI = get_rsi(sdat3,j,memory)\n",
    "        #print(\"RSI:\",RSI)\n",
    "\n",
    "        MFI = get_mfi(sdat3,j,memory)\n",
    "        #print(\"MFI:\",MFI)\n",
    "\n",
    "        EMA = get_ema(sdat3,j,memory,EMAp)\n",
    "        EMAp = EMA\n",
    "\n",
    "        SO = get_so(sdat3,j,memory)\n",
    "\n",
    "        N_close = sdat3[j+1,3]\n",
    "\n",
    "        rec1 = [sdat3[j,2],sdat3[j,0],sdat3[j,1],sdat3[j,3],sdat3[j,4],RSI,MFI,EMA,SO,N_close]\n",
    "        rec2 = [sdat3[j,3],RSI,MFI,EMA,SO,N_close]\n",
    "\n",
    "        if(sdat3[j,4]!=0):\n",
    "            d1 = {\"Open\":sdat3[j,2],\"High\":sdat3[j,0],\"Low\":sdat3[j,1],\"Close\":sdat3[j,3],\"Volume\":sdat3[j,4],\"RSI\":RSI,\"MFI\":MFI,\"EMA\":EMA,\"SO\":SO,\"CloseNext\":N_close}\n",
    "            df1.loc[i] = rec1\n",
    "            df2.loc[i] = rec2\n",
    "\n",
    "    #ANN\n",
    "    dataset = df1\n",
    "    y = pd.DataFrame(dataset['CloseNext'])\n",
    "    X = dataset.drop(['CloseNext'], axis = 1)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #X = X[1700:2030,:]\n",
    "    #y = y[1700:2030,:]\n",
    "    y = y.flatten()\n",
    "\n",
    "    #Feature scaling\n",
    "    scaled = StandardScaler()\n",
    "    scaled.fit(X)\n",
    "    X = scaled.transform(X)\n",
    "\n",
    "    #Train Test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "    ## ANN implementation\n",
    "    # define base model of our neural network for regression taks\n",
    "    def endgame():\n",
    "        # Adding the neurons in various layers\n",
    "        model = Sequential()\n",
    "        model.add(Dense(9, input_dim=9, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # Compile model for our use in KerasRegressor\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mape'])\n",
    "        return model\n",
    "\n",
    "    ann_regression = KerasRegressor(build_fn = endgame, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "    ann_regression.fit(X_train,y_train)\n",
    "\n",
    "    ann_predict = ann_regression.predict(X_test)\n",
    "\n",
    "    error = mean_absolute_error(ann_predict,y_test)\n",
    "    per_err = (error/np.mean(y_test)) * 100\n",
    "    print('The mean absolute error is {} and percentage error is {}.'.format(error,per_err))\n",
    "    \n",
    "    return ann_regression, scaled, df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tutorial-syntax",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-fed9038c8ae3>:90: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  SO = ((sdata[m,3]-sdata[m,1])/(sdata[m,0]-sdata[m,1]))*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 832413.8423 - mape: 98.9987\n",
      "Epoch 2/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 250155.4067 - mape: 45.3383\n",
      "Epoch 3/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 43139.4495 - mape: 21.6647\n",
      "Epoch 4/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 28393.3504 - mape: 17.9030\n",
      "Epoch 5/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 20132.7643 - mape: 15.2533\n",
      "Epoch 6/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 11430.6332 - mape: 11.7479\n",
      "Epoch 7/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 4515.4443 - mape: 8.3131\n",
      "Epoch 8/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 1693.4615 - mape: 5.4030\n",
      "Epoch 9/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 793.5651 - mape: 3.7134\n",
      "Epoch 10/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 684.9593 - mape: 2.8892\n",
      "Epoch 11/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 503.7964 - mape: 2.4721\n",
      "Epoch 12/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 493.4009 - mape: 2.1763\n",
      "Epoch 13/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 456.7225 - mape: 1.8998\n",
      "Epoch 14/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 513.0656 - mape: 1.9413\n",
      "Epoch 15/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 421.4688 - mape: 1.7837\n",
      "Epoch 16/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 454.6215 - mape: 1.7415\n",
      "Epoch 17/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 418.5114 - mape: 1.7578\n",
      "Epoch 18/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 460.3952 - mape: 1.6668\n",
      "Epoch 19/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 454.8223 - mape: 1.6362\n",
      "Epoch 20/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 489.8550 - mape: 1.6905\n",
      "Epoch 21/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 391.0484 - mape: 1.6050\n",
      "Epoch 22/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 390.1911 - mape: 1.5698\n",
      "Epoch 23/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 384.7959 - mape: 1.6022\n",
      "Epoch 24/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 386.8622 - mape: 1.5760\n",
      "Epoch 25/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 354.6850 - mape: 1.4961\n",
      "Epoch 26/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 384.5960 - mape: 1.5970\n",
      "Epoch 27/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 427.5534 - mape: 1.5583\n",
      "Epoch 28/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 370.0822 - mape: 1.5714\n",
      "Epoch 29/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 388.1847 - mape: 1.5455\n",
      "Epoch 30/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 361.2153 - mape: 1.5856\n",
      "Epoch 31/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 436.1151 - mape: 1.6097\n",
      "Epoch 32/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 420.2309 - mape: 1.5781\n",
      "Epoch 33/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 373.8461 - mape: 1.5927\n",
      "Epoch 34/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 403.6172 - mape: 1.5909\n",
      "Epoch 35/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 414.1589 - mape: 1.6204\n",
      "Epoch 36/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 440.1025 - mape: 1.5592\n",
      "Epoch 37/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 429.1366 - mape: 1.5819\n",
      "Epoch 38/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 456.4208 - mape: 1.6177\n",
      "Epoch 39/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 386.6338 - mape: 1.5479\n",
      "Epoch 40/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 407.0783 - mape: 1.6225\n",
      "Epoch 41/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 477.3464 - mape: 1.6437\n",
      "Epoch 42/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 406.3146 - mape: 1.5890\n",
      "Epoch 43/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 394.3548 - mape: 1.5490\n",
      "Epoch 44/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 485.6389 - mape: 1.6794\n",
      "Epoch 45/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 412.1256 - mape: 1.5801\n",
      "Epoch 46/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 416.6286 - mape: 1.6033\n",
      "Epoch 47/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 415.5676 - mape: 1.6416\n",
      "Epoch 48/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 431.1491 - mape: 1.6242\n",
      "Epoch 49/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 405.9281 - mape: 1.5333\n",
      "Epoch 50/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 402.8777 - mape: 1.5252\n",
      "Epoch 51/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 401.5873 - mape: 1.5169\n",
      "Epoch 52/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 428.1717 - mape: 1.5528\n",
      "Epoch 53/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 477.5442 - mape: 1.5757\n",
      "Epoch 54/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 368.8239 - mape: 1.5358\n",
      "Epoch 55/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 421.9311 - mape: 1.5351\n",
      "Epoch 56/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 349.7947 - mape: 1.5436\n",
      "Epoch 57/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 410.2110 - mape: 1.5836\n",
      "Epoch 58/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 398.7136 - mape: 1.5905\n",
      "Epoch 59/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 419.5173 - mape: 1.6064\n",
      "Epoch 60/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 366.6277 - mape: 1.5394\n",
      "Epoch 61/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 539.8624 - mape: 1.6011\n",
      "Epoch 62/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 435.4103 - mape: 1.5512\n",
      "Epoch 63/100\n",
      "349/349 [==============================] - 1s 2ms/step - loss: 473.0294 - mape: 1.5466\n",
      "Epoch 64/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 422.8935 - mape: 1.5735\n",
      "Epoch 65/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 462.3472 - mape: 1.5709\n",
      "Epoch 66/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 416.1553 - mape: 1.5504\n",
      "Epoch 67/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 363.4918 - mape: 1.4601\n",
      "Epoch 68/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 392.1276 - mape: 1.5733\n",
      "Epoch 69/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 388.7973 - mape: 1.5430\n",
      "Epoch 70/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 358.1880 - mape: 1.4512\n",
      "Epoch 71/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 386.8695 - mape: 1.5393\n",
      "Epoch 72/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 483.8134 - mape: 1.5762\n",
      "Epoch 73/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 404.9586 - mape: 1.5415\n",
      "Epoch 74/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 364.8455 - mape: 1.5090\n",
      "Epoch 75/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 516.7057 - mape: 1.6989\n",
      "Epoch 76/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 433.5852 - mape: 1.5408\n",
      "Epoch 77/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 427.4113 - mape: 1.5052\n",
      "Epoch 78/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 364.9646 - mape: 1.4838\n",
      "Epoch 79/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 383.4105 - mape: 1.5093\n",
      "Epoch 80/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 482.6957 - mape: 1.5472\n",
      "Epoch 81/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 483.1304 - mape: 1.5458\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 0s 1ms/step - loss: 440.4510 - mape: 1.6041\n",
      "Epoch 83/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 361.6035 - mape: 1.4526\n",
      "Epoch 84/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 440.8601 - mape: 1.5388\n",
      "Epoch 85/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 422.7699 - mape: 1.5462\n",
      "Epoch 86/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 379.0153 - mape: 1.4887\n",
      "Epoch 87/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 470.6535 - mape: 1.6060\n",
      "Epoch 88/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 445.6549 - mape: 1.5826\n",
      "Epoch 89/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 394.3830 - mape: 1.5249\n",
      "Epoch 90/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 406.5718 - mape: 1.4924\n",
      "Epoch 91/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 460.5757 - mape: 1.6292\n",
      "Epoch 92/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 445.4810 - mape: 1.5064\n",
      "Epoch 93/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 389.7519 - mape: 1.5070\n",
      "Epoch 94/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 410.9704 - mape: 1.5097\n",
      "Epoch 95/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 377.8205 - mape: 1.5051\n",
      "Epoch 96/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 466.8118 - mape: 1.5954\n",
      "Epoch 97/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 385.8946 - mape: 1.4881\n",
      "Epoch 98/100\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 429.4069 - mape: 1.5635\n",
      "Epoch 99/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 355.2749 - mape: 1.4820\n",
      "Epoch 100/100\n",
      "349/349 [==============================] - 1s 1ms/step - loss: 444.6781 - mape: 1.5665\n",
      "150/150 [==============================] - 0s 1ms/step\n",
      "The mean absolute error is 11.282299225343102 and percentage error is 1.467028644233138.\n"
     ]
    }
   ],
   "source": [
    "#parameter\n",
    "start_year = 2011\n",
    "start_month = 1\n",
    "start_day = 1\n",
    "code = \"RELIANCE.NS\"\n",
    "\n",
    "ann_regression, scaled, df1  = predict_clossing_price(start_year, start_month, start_day, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ceramic-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(2193.2798, dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"2207\t2215.100098\t2170.25\t2181.949951\t5316182\t48.38902871\t55.85965509\t2133.179793\t26.08678937\"\n",
    "X = [[float(i) for i in text.split()]]\n",
    "ann_regression.predict(scaled.transform(np.array(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "recreational-grave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MFI</th>\n",
       "      <th>EMA</th>\n",
       "      <th>SO</th>\n",
       "      <th>CloseNext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>482.922363</td>\n",
       "      <td>491.590210</td>\n",
       "      <td>481.931763</td>\n",
       "      <td>488.766968</td>\n",
       "      <td>9012481.0</td>\n",
       "      <td>54.901661</td>\n",
       "      <td>37.582003</td>\n",
       "      <td>506.609041</td>\n",
       "      <td>70.769191</td>\n",
       "      <td>481.238342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492.878021</td>\n",
       "      <td>493.274261</td>\n",
       "      <td>477.523560</td>\n",
       "      <td>481.238342</td>\n",
       "      <td>10265008.0</td>\n",
       "      <td>51.823167</td>\n",
       "      <td>30.253539</td>\n",
       "      <td>503.226281</td>\n",
       "      <td>23.584871</td>\n",
       "      <td>474.749847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483.962524</td>\n",
       "      <td>487.850677</td>\n",
       "      <td>473.635406</td>\n",
       "      <td>474.749847</td>\n",
       "      <td>9380240.0</td>\n",
       "      <td>49.922295</td>\n",
       "      <td>21.880954</td>\n",
       "      <td>499.429423</td>\n",
       "      <td>7.839745</td>\n",
       "      <td>466.924042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>478.464630</td>\n",
       "      <td>479.158051</td>\n",
       "      <td>465.586700</td>\n",
       "      <td>466.924042</td>\n",
       "      <td>12970523.0</td>\n",
       "      <td>53.557356</td>\n",
       "      <td>13.980960</td>\n",
       "      <td>495.095373</td>\n",
       "      <td>9.854151</td>\n",
       "      <td>452.213470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>468.063232</td>\n",
       "      <td>468.509003</td>\n",
       "      <td>446.765106</td>\n",
       "      <td>452.213470</td>\n",
       "      <td>15624401.0</td>\n",
       "      <td>52.254094</td>\n",
       "      <td>13.454348</td>\n",
       "      <td>489.377786</td>\n",
       "      <td>25.056982</td>\n",
       "      <td>455.333893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2180.000000</td>\n",
       "      <td>2189.949951</td>\n",
       "      <td>2157.699951</td>\n",
       "      <td>2175.850098</td>\n",
       "      <td>9892597.0</td>\n",
       "      <td>49.144867</td>\n",
       "      <td>56.481724</td>\n",
       "      <td>2092.515562</td>\n",
       "      <td>56.279522</td>\n",
       "      <td>2178.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2156.000000</td>\n",
       "      <td>2211.949951</td>\n",
       "      <td>2153.050049</td>\n",
       "      <td>2178.699951</td>\n",
       "      <td>11773630.0</td>\n",
       "      <td>42.485238</td>\n",
       "      <td>62.532582</td>\n",
       "      <td>2104.006814</td>\n",
       "      <td>43.548295</td>\n",
       "      <td>2191.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>2168.500000</td>\n",
       "      <td>2231.899902</td>\n",
       "      <td>2168.000000</td>\n",
       "      <td>2191.100098</td>\n",
       "      <td>9002404.0</td>\n",
       "      <td>41.351413</td>\n",
       "      <td>62.466791</td>\n",
       "      <td>2115.619252</td>\n",
       "      <td>36.150444</td>\n",
       "      <td>2191.050049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>2200.000000</td>\n",
       "      <td>2213.800049</td>\n",
       "      <td>2146.600098</td>\n",
       "      <td>2191.050049</td>\n",
       "      <td>6993792.0</td>\n",
       "      <td>47.438579</td>\n",
       "      <td>56.734076</td>\n",
       "      <td>2125.676691</td>\n",
       "      <td>66.145808</td>\n",
       "      <td>2181.949951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2207.000000</td>\n",
       "      <td>2215.100098</td>\n",
       "      <td>2170.250000</td>\n",
       "      <td>2181.949951</td>\n",
       "      <td>5316182.0</td>\n",
       "      <td>48.389029</td>\n",
       "      <td>55.859655</td>\n",
       "      <td>2133.179793</td>\n",
       "      <td>26.086789</td>\n",
       "      <td>2137.600098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2493 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open         High          Low        Close      Volume  \\\n",
       "0      482.922363   491.590210   481.931763   488.766968   9012481.0   \n",
       "1      492.878021   493.274261   477.523560   481.238342  10265008.0   \n",
       "2      483.962524   487.850677   473.635406   474.749847   9380240.0   \n",
       "3      478.464630   479.158051   465.586700   466.924042  12970523.0   \n",
       "4      468.063232   468.509003   446.765106   452.213470  15624401.0   \n",
       "...           ...          ...          ...          ...         ...   \n",
       "2490  2180.000000  2189.949951  2157.699951  2175.850098   9892597.0   \n",
       "2491  2156.000000  2211.949951  2153.050049  2178.699951  11773630.0   \n",
       "2492  2168.500000  2231.899902  2168.000000  2191.100098   9002404.0   \n",
       "2493  2200.000000  2213.800049  2146.600098  2191.050049   6993792.0   \n",
       "2494  2207.000000  2215.100098  2170.250000  2181.949951   5316182.0   \n",
       "\n",
       "            RSI        MFI          EMA         SO    CloseNext  \n",
       "0     54.901661  37.582003   506.609041  70.769191   481.238342  \n",
       "1     51.823167  30.253539   503.226281  23.584871   474.749847  \n",
       "2     49.922295  21.880954   499.429423   7.839745   466.924042  \n",
       "3     53.557356  13.980960   495.095373   9.854151   452.213470  \n",
       "4     52.254094  13.454348   489.377786  25.056982   455.333893  \n",
       "...         ...        ...          ...        ...          ...  \n",
       "2490  49.144867  56.481724  2092.515562  56.279522  2178.699951  \n",
       "2491  42.485238  62.532582  2104.006814  43.548295  2191.100098  \n",
       "2492  41.351413  62.466791  2115.619252  36.150444  2191.050049  \n",
       "2493  47.438579  56.734076  2125.676691  66.145808  2181.949951  \n",
       "2494  48.389029  55.859655  2133.179793  26.086789  2137.600098  \n",
       "\n",
       "[2493 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "distinct-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "discrete-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[492.7789612,\n",
       "  519.5749512,\n",
       "  492.3826904,\n",
       "  509.5202637,\n",
       "  14236238.0,\n",
       "  77.73335338,\n",
       "  63.17854158,\n",
       "  478.6916457,\n",
       "  63.02371621]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-chamber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
